import os
import re
import requests
import json
from pathlib import Path


def get_lmstudio_model_name():
    try:
        response = requests.get("http://localhost:1234/v1/models")
        response.raise_for_status()
        models = response.json().get("data", [])
        if models:
            return models[0]["id"] 
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
    return None

def clean_text(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤, –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤."""
    text = text.replace("\r", " ").replace("\n", " ")  # —É–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã
    text = re.sub(r"\s+", " ", text)  # –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r"[^\w\s.,!?-]", "", text)  # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    return text.strip()



def generate_summary(text: str, method: str = "lmstudio", api_url: str = None, api_key: str = None) -> str:
    """
    Generate summary and key points for transcript.
    """
    try:
        if method == "lmstudio":
            model_name = get_lmstudio_model_name()
            print("–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å:", model_name)
            url = api_url or "http://localhost:1234/v1/chat/completions"
            clean = clean_text(text)
            payload = {
                "model": model_name,  
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —Å–æ–≤–µ—â–∞–Ω–∏—è."},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è:\n\n{clean}\n\n–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤) –∏ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."}
                ],
                "temperature": 0.3,
                "stream": False
            }
            print("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ LM Studio:")
            print(json.dumps(payload, ensure_ascii=False, indent=2))

            headers = {"Content-Type": "application/json"}
            response = requests.post(url, headers=headers, json=payload, timeout=1200)
            response.raise_for_status()
            data = response.json()

            # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞
            try:
                return data["choices"][0]["message"]["content"].strip()
            except KeyError:
                return data["choices"][0]["messages"][0]["content"].strip()


        elif method == "openai":
            url = api_url or "https://api.openai.com/v1/chat/completions"
            payload = {
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —Å–æ–≤–µ—â–∞–Ω–∏—è."},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è:\n\n{text}\n\n–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤) –∏ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."}
                ],
                "temperature": 0.3
            }
            headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"].strip()

        elif method == "deepseek":
            url = api_url or "https://api.deepseek.com/chat/completions"
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —Å–æ–≤–µ—â–∞–Ω–∏—è."},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è:\n\n{text}\n\n–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤) –∏ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."}
                ],
                "temperature": 0.3,
                "stream": False
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"].strip()

        elif method == "huggingface":
            url = api_url or "https://api-inference.huggingface.co/models/facebook/bart-large-cnn"
            headers = {"Authorization": f"Bearer {api_key}"}
            response = requests.post(url, headers=headers, json={"inputs": text})
            response.raise_for_status()
            data = response.json()
            return data[0]["summary_text"]

        elif method == "dummy":
            return "‚ö†Ô∏è –°–∞–º–º–∞—Ä–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LM Studio –∏–ª–∏ API)."

        else:
            raise ValueError(f"Unknown summarization method: {method}")

    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏: {e}"


def summarize_transcripts(input_folder: str, method: str = "lmstudio", api_url: str = None, api_key: str = None):
    """
    Process all transcript .txt files in folder and generate summaries.
    Saves each summary as <filename>.summary.txt
    """
    for file_name in os.listdir(input_folder):
        # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ summary
        if not file_name.endswith(".txt") or file_name.endswith(".summary.txt"):
            continue

        file_path = os.path.join(input_folder, file_name)
        with open(file_path, "r", encoding="utf-8") as f:
            transcript = f.read().strip()

        if not transcript:
            print(f"‚ö†Ô∏è Empty transcript: {file_name}")
            continue

        print(f"üìù Summarizing: {file_name}")
        summary = generate_summary(transcript, method=method, api_url=api_url, api_key=api_key)

        summary_path = os.path.join(input_folder, f"{Path(file_name).stem}.summary.txt")
        with open(summary_path, "w", encoding="utf-8") as f:
            f.write(summary)

        print(f"‚úÖ Summary saved: {summary_path}")

