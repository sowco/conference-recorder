import os
import requests
import json
from pathlib import Path

def generate_summary(text: str, method: str = "lmstudio", api_url: str = None, api_key: str = None) -> str:
    """
    Generate summary and key points for transcript.
    """
    try:
        if method == "lmstudio":
            url = api_url or "http://localhost:1234/v1/chat/completions"
            payload = {
                "model": "local-model",
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —Å–æ–≤–µ—â–∞–Ω–∏—è. –ù–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π."},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è:\n\n{text}\n\n–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤) –∏ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤. –ù–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π."}
                ],
                "temperature": 0.3
            }
            headers = {"Content-Type": "application/json"}
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"].strip()

        elif method == "openai":
            url = api_url or "https://api.openai.com/v1/chat/completions"
            payload = {
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —Å–æ–≤–µ—â–∞–Ω–∏—è."},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è:\n\n{text}\n\n–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤) –∏ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."}
                ],
                "temperature": 0.3
            }
            headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"].strip()

        elif method == "deepseek":
            url = api_url or "https://api.deepseek.com/chat/completions"
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –ø–æ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–µ —Å–æ–≤–µ—â–∞–Ω–∏—è."},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è:\n\n{text}\n\n–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤) –∏ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."}
                ],
                "temperature": 0.3,
                "stream": False
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"].strip()

        elif method == "huggingface":
            url = api_url or "https://api-inference.huggingface.co/models/facebook/bart-large-cnn"
            headers = {"Authorization": f"Bearer {api_key}"}
            response = requests.post(url, headers=headers, json={"inputs": text})
            response.raise_for_status()
            data = response.json()
            return data[0]["summary_text"]

        elif method == "dummy":
            return "‚ö†Ô∏è –°–∞–º–º–∞—Ä–∏ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LM Studio –∏–ª–∏ API)."

        else:
            raise ValueError(f"Unknown summarization method: {method}")

    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∞–º–º–∞—Ä–∏: {e}"


def summarize_transcripts(input_folder: str, method: str = "lmstudio", api_url: str = None, api_key: str = None):
    """
    Process all transcript .txt files in folder and generate summaries.
    Saves each summary as <filename>.summary.txt
    """
    for file_name in os.listdir(input_folder):
        # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ summary
        if not file_name.endswith(".txt") or file_name.endswith(".summary.txt"):
            continue

        file_path = os.path.join(input_folder, file_name)
        with open(file_path, "r", encoding="utf-8") as f:
            transcript = f.read().strip()

        if not transcript:
            print(f"‚ö†Ô∏è Empty transcript: {file_name}")
            continue

        print(f"üìù Summarizing: {file_name}")
        summary = generate_summary(transcript, method=method, api_url=api_url, api_key=api_key)

        summary_path = os.path.join(input_folder, f"{Path(file_name).stem}.summary.txt")
        with open(summary_path, "w", encoding="utf-8") as f:
            f.write(summary)

        print(f"‚úÖ Summary saved: {summary_path}")

